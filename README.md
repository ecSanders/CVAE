# Overview

The goal of this project was to give me hands on experience working with autoencoders and a generative deep learning architecture.

This project loads the MNIST dataset (TensorFlow repo), defines a CVAE architecture, defines its loss and optimizers, and trains on it. It trains in apprixmately 2-3 epochs with decent outcomes. 


[CVAE Demo](https://www.loom.com/share/034679546577493da8407d9373ac4302)

# Development Environment

Tools that were used in this developement were the Jupyter Notebooks, Keras, TensorFlow, and Numpy.

# Useful Websites

{Make a list of websites that you found helpful in this project}

- [intellipaat](https://intellipaat.com/community/500/what-is-the-meaning-of-the-word-logits-in-tensorflow)
- [towardsdatascience](https://towardsdatascience.com/understanding-conditional-variational-autoencoders-cd62b4f57bf8)

# Future Work

- Implement this using the celeba dataset
- Increase model complexity
- Try and stack this with another model
